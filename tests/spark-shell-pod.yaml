# Spark configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-shell-config
  namespace: spark
data:
  spark-defaults.conf: |
    spark.master                    spark://spark-arm-master:7077
    spark.driver.memory            1g
    spark.executor.memory          1g
    spark.hive.metastore.uris      thrift://spark-arm-hive:9083
    spark.driver.extraJavaOptions  -Djline.terminal=jline.UnsupportedTerminal
    spark.hadoop.fs.s3a.impl       org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.aws.credentials.provider  org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
---
# AWS credentials (to be replaced with actual values)
apiVersion: v1
kind: Secret
metadata:
  name: spark-aws-credentials
  namespace: spark
type: Opaque
stringData:
  aws-endpoint-url: ${AWS_ENDPOINT_URL}
  aws-access-key-id: ${AWS_ACCESS_KEY_ID}
  aws-secret-access-key: ${AWS_SECRET_ACCESS_KEY}
---
# Spark shell pod
apiVersion: v1
kind: Pod
metadata:
  name: spark-shell-pod
  namespace: spark
spec:
  containers:
    - name: spark-shell
      image: ghcr.io/openbiocure/spark-arm:latest
      stdin: true
      tty: true
      command: ["/opt/spark/bin/spark-shell"]
      volumeMounts:
        - name: spark-config
          mountPath: /opt/spark/conf/spark-defaults.conf
          subPath: spark-defaults.conf
      env:
        - name: AWS_ENDPOINT_URL
          valueFrom:
            secretKeyRef:
              name: spark-aws-credentials
              key: aws-endpoint-url
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: spark-aws-credentials
              key: aws-access-key-id
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: spark-aws-credentials
              key: aws-secret-access-key
  volumes:
    - name: spark-config
      configMap:
        name: spark-shell-config
  restartPolicy: Never
